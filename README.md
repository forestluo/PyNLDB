# PyNLDB

 基于Python和NLDB的数据处理程序。主要是实现断句，分词和词性检测等功能。

 数据库的内容过大（超过40G），无法在Github上免费分享。因此没有选择上传（如有需要，请捐助之后联系）。

 数据文件均以json格式保存在本地。考虑数据量比较大（原始数据超过5G），未来将会增加爬虫机制，直接从互联网获得原始数据进行分析。

# 参考链接

www.algmain.com

我的NLP（自然语言处理）历程（8）——频次统计：https://zhuanlan.zhihu.com/p/539109593

我的NLP（自然语言处理）历程（9）——词典导入：https://zhuanlan.zhihu.com/p/539464788

我的NLP（自然语言处理）历程（10）——相关系数：https://zhuanlan.zhihu.com/p/541794935

我的NLP（自然语言处理）历程（11）——疯狂的麦克斯：https://zhuanlan.zhihu.com/p/542073251

我的NLP（自然语言处理）历程（12）——分词算法：https://zhuanlan.zhihu.com/p/542550863

我的NLP（自然语言处理）历程（13）——断句算法：https://zhuanlan.zhihu.com/p/542904661

我的NLP（自然语言处理）历程（14）——基于相关系数的分词算法：https://zhuanlan.zhihu.com/p/552443996

我的NLP（自然语言处理）历程（15）——相关系数与词性检测：https://zhuanlan.zhihu.com/p/555630299

我的NLP（自然语言处理）历程（16）——提取数量词：https://zhuanlan.zhihu.com/p/557053336

我的NLP（自然语言处理）历程（17）——信息熵与分词：https://zhuanlan.zhihu.com/p/557433900

我的NLP（自然语言处理）历程（18）——分词最后环节：https://zhuanlan.zhihu.com/p/558171316

我的NLP（自然语言处理）历程（19）——词性检测：https://zhuanlan.zhihu.com/p/560504920

---

给作者捐赠：

<div align=center>
<img src="https://github.com/forestluo/AlgMain/blob/main/weixin.jpg" width="210px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://github.com/forestluo/AlgMain/blob/main/zhifubao.jpg" width="210px">
</div>
